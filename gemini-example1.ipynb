{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad5023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuration\n",
    "csv_file_path = 'newTestingData.csv' # Ensure this file is in your notebook's directory\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "EMBEDDING_DIM = 64 # Size of the vector space for parts\n",
    "LSTM_UNITS = 100   # Number of memory units in the LSTM\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04e6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Keep only necessary columns\n",
    "df = df[['CUST_ORDER_ID', 'PART_ID', 'LOCATION_RANK']]\n",
    "\n",
    "# Drop rows with missing critical values\n",
    "df.dropna(subset=['PART_ID', 'LOCATION_RANK'], inplace=True)\n",
    "\n",
    "# Sort by Order ID and then by Rank to ensure the sequence is chronological\n",
    "df = df.sort_values(by=['CUST_ORDER_ID', 'LOCATION_RANK'])\n",
    "\n",
    "# Convert PART_ID to string so it is treated as a categorical label, not a number\n",
    "df['PART_ID'] = df['PART_ID'].astype(str)\n",
    "\n",
    "print(f\"Data Loaded: {len(df)} rows.\")\n",
    "print(\"Sample of sorted data:\")\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d60a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Label Encode Part IDs (Convert string IDs to integers 0, 1, 2...)\n",
    "label_encoder = LabelEncoder()\n",
    "df['PART_ID_ENCODED'] = label_encoder.fit_transform(df['PART_ID'])\n",
    "\n",
    "# Calculate vocabulary size (Total unique parts) + 1 for padding\n",
    "vocab_size = len(label_encoder.classes_) + 1\n",
    "print(f\"Unique Parts (Vocabulary Size): {vocab_size}\")\n",
    "\n",
    "# 2. Group by Order to get sequences\n",
    "# This creates a list of lists, where each inner list is an order sequence\n",
    "order_sequences = df.groupby('CUST_ORDER_ID')['PART_ID_ENCODED'].apply(list).values\n",
    "\n",
    "# 3. Create N-gram sequences for training\n",
    "input_sequences = []\n",
    "for sequence in order_sequences:\n",
    "    # We need at least 2 parts to predict the next one\n",
    "    if len(sequence) > 1:\n",
    "        for i in range(1, len(sequence)):\n",
    "            # Take the first i+1 parts (e.g., [Part1, Part2])\n",
    "            n_gram_sequence = sequence[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# 4. Pad sequences\n",
    "# Determine the maximum length of any sequence in the data\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "print(f\"Max Sequence Length: {max_sequence_len}\")\n",
    "\n",
    "# Pad sequences with 0s at the beginning so they are all the same length\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# 5. Split into Features (X) and Target (y)\n",
    "# X is everything except the last item, y is the last item\n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "\n",
    "print(f\"Total Training Sequences Generated: {len(X)}\")\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e032dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Embedding Layer: Turns integer Part IDs into dense vectors\n",
    "# input_length is max_sequence_len - 1 because we removed the label column\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    input_length=max_sequence_len-1))\n",
    "\n",
    "# LSTM Layer\n",
    "model.add(LSTM(LSTM_UNITS))\n",
    "model.add(Dropout(0.2)) # Randomly drop neurons to prevent overfitting\n",
    "\n",
    "# Output Layer\n",
    "# Softmax gives us a probability distribution over all possible parts\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e89b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "# Plot Training Accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_part(model, tokenizer, current_sequence):\n",
    "    \"\"\"\n",
    "    Predicts the next part based on the current sequence of parts.\n",
    "    \"\"\"\n",
    "    # 1. Encode the input sequence using the same label encoder as training\n",
    "    encoded_seq = []\n",
    "    for part in current_sequence:\n",
    "        try:\n",
    "            # Transform string part ID to integer\n",
    "            encoded_id = tokenizer.transform([str(part)])[0]\n",
    "            encoded_seq.append(encoded_id)\n",
    "        except ValueError:\n",
    "            # Skip parts that were never seen during training\n",
    "            print(f\"Warning: Part '{part}' not found in training data.\")\n",
    "            continue\n",
    "            \n",
    "    if not encoded_seq:\n",
    "        return \"Unknown Sequence\"\n",
    "\n",
    "    # 2. Pad the sequence to match the model's expected input length\n",
    "    padded_seq = pad_sequences([encoded_seq], maxlen=max_sequence_len-1, padding='pre')\n",
    "    \n",
    "    # 3. Get predictions (probabilities)\n",
    "    predictions = model.predict(padded_seq, verbose=0)\n",
    "    \n",
    "    # 4. Get the index of the highest probability\n",
    "    predicted_index = np.argmax(predictions, axis=-1)[0]\n",
    "    \n",
    "    # 5. Convert integer back to Part ID string\n",
    "    predicted_part = tokenizer.inverse_transform([predicted_index])[0]\n",
    "    \n",
    "    return predicted_part\n",
    "\n",
    "print(\"Prediction function ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d398438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pick a random order to test ---\n",
    "import random\n",
    "\n",
    "# Get a random order ID from the data\n",
    "random_order_id = random.choice(df['CUST_ORDER_ID'].unique())\n",
    "print(f\"Testing Order ID: {random_order_id}\")\n",
    "\n",
    "# Get the actual sequence for this order\n",
    "actual_sequence_df = df[df['CUST_ORDER_ID'] == random_order_id].sort_values('LOCATION_RANK')\n",
    "actual_sequence = actual_sequence_df['PART_ID'].tolist()\n",
    "\n",
    "if len(actual_sequence) < 2:\n",
    "    print(\"Order too short to test prediction (needs at least 2 items).\")\n",
    "else:\n",
    "    # Use all parts except the last one as input\n",
    "    input_parts = actual_sequence[:-1]\n",
    "    \n",
    "    # The actual next part (Ground Truth)\n",
    "    correct_next_part = actual_sequence[-1]\n",
    "    \n",
    "    print(f\"Input Sequence: {input_parts}\")\n",
    "    print(f\"Actual Next Part: {correct_next_part}\")\n",
    "    \n",
    "    # Ask Model\n",
    "    prediction = predict_next_part(model, label_encoder, input_parts)\n",
    "    print(f\"Model Predicted:  {prediction}\")\n",
    "    \n",
    "    if prediction == correct_next_part:\n",
    "        print(\"✅ SUCCESS! The model predicted correctly.\")\n",
    "    else:\n",
    "        print(\"❌ INCORRECT. Prediction mismatch.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
